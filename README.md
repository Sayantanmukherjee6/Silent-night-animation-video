# Silent-night-animation-video

# Result
- ![Final Video](https://github.com/Sayantanmukherjee6/Silent-night-animation-video/blob/main/Final_video.mp4)

# Requirement
- A good local workstation with Nvidia GPU having atleast 12GB Vram (I generally prefer Nvidia RTX 3060 12 GB VRAM for testing and Nvidia RTX 5090 with 32 GB VRAM for final generation). Runpod/Simplepod works best for people who can't afford those GPUs. I prefer Simplepod to Runpod for the price of GPUs.
- Python >= 3.11.
- Cuda >= 12.6.
- ComfyUI (After downloading please ensure to update ComfyUI and install the required python packages in requirements.txt inside ComfyUI folder).
- ComfyUI custom nodes for worflow - Download them using ComfyUI Manager.
- ChatGPT/Gemini/Claude/Grok - For generating prompts and base image(Base Image can also be generated by using QWEN Edit workflow added in this repo).
- IMovie/DaVinci resolve/Capcut/Any good video editing tool - For editing, joining and creating full video with audio from multiple video/audio segments.
- (Optional) Suno AI - For creating own music using AI 
- PATIENCE (Most important).

# Workflows
- [Qwen Edit](https://github.com/Sayantanmukherjee6/Silent-night-animation-video/blob/main/image_qwen_image_edit_2509.json) - This can be also found under ComfyUI templates.
- [I2V Extend](https://github.com/Sayantanmukherjee6/Silent-night-animation-video/blob/main/i2v_workflow_final_15secs_.json) - This I created on top of Wan2.2 I2V ComfyUI template, this workflow can generate long consistent videos depending on System and GPU Ram.
- [Infinite Talk](https://github.com/Sayantanmukherjee6/Silent-night-animation-video/blob/main/wan_infinite_talk.json) - This workflow I got from [ComfyUIStudio](https://www.youtube.com/@ComfyUIstudio) 

# Steps to generate such video
- I started with the music first as I wanted to create an animated video for Christmas. I went to youtube and downloaded the mp3 version of this video ["Silent Night" - (Sister Duet) - Lucy & Martha Thomas - Christmas Carol
](https://www.youtube.com/watch?v=UyXsWGNCJbA). After downloading the mp3, I trimmed it down to 1 min.
- I further created 4 short mp3's out of the 1 min trimmed mp3 based on the story I had in mind.
- Story boarding - Most important creative part, I mainly use ChatGpt for storyboarding based on the mp3 and the idea I have on mind, but unfortunately for creating this video ChatGPT was not much of a help for me, so I did it manually on a piece of paper by myself based on the ideas I had.
- Generate a base image of the character using ChatGPT/Gemini/Grok/QWEN edit workflow(Added in repo). Best kind of image would be a full portrait of a character(from head to toes) standing infront of a white/green background.
- Once the base image ready, open image_qwen_image_edit_2509.json workflow in JSON and download the required models in respective directory under ComfyUI/models. Once the models are downloaded, restart ComfyUI and start generating images for the scenes based on the base image. I generated four scenes (ComfyUI_00034_.png, ComfyUI_00037_.png, ComfyUI_00038_.png, download (2).png all uploaded in this repo). This is the most time taking process as images might lack in facial, dress and background consistency. If you have a lora trained for the enviornment or character then I feel it would be much easier. But I faced issue with consistency, so I tinkered with the parameters and generated about 15/20 images per prompt and selected 1 image out of them. Here is a snapshot of the workflow:
![Qwen Edit](https://github.com/Sayantanmukherjee6/Silent-night-animation-video/blob/main/Qwen-image-edit.png)
Here are some of the prompt I used to generate this images:
> A highly realistic indoor night scene of a woman standing beside a window in her home. She is wearing a grey sweater and denim jeans. Soft, dim warm light illuminates the room from inside, creating gentle shadows. Outside the window, snow is falling quietly in the night. The woman is calmly looking out through the window; her face is partially visible from a side profile. Serene and peaceful winter Christmas atmosphere. Cinematic low-angle shot, side-view composition, shallow depth of field, natural skin tones, realistic lighting, photorealistic style.
> 
> A highly realistic indoor night scene of a woman wearing a grey sweater and denim jeans, gently walking toward her sleeping child in a cradle. The room is softly lit with dim, warm indoor lighting, creating a calm and intimate atmosphere. The child is peacefully sleeping in the cradle. The window is positioned at a clear distance from the cradle, with open space between them, avoiding overlap in composition. The womanâ€™s posture is gentle and careful, expressing quiet care and tenderness. Serene winter Christmas mood. Cinematic mid-angle photography, natural proportions, realistic lighting, photorealistic style.
>
- I generated 4 lipsync videos with Infinite-talk workflow along with 4 short mp3s and download (2).png. Lipsync was not at all perfect enough, so now my focus will be enhancing the infinite-talk workflow, anyway here is a snapshot of the workflow:
![Infinite talk](https://github.com/Sayantanmukherjee6/Silent-night-animation-video/blob/main/infinite-talk.png)
- I generated 4 short videos with i2v_workflow_final_15secs_.json along with ComfyUI_00034_.png, ComfyUI_00037_.png, ComfyUI_00038_.png. I had a lora trained for Wan2.2 low noise but unfortunately the trained lora was not upto the mark, so I had to use I2V instead of T2V. Here is a snapshot of the workflow:
![I2V Workflow](https://github.com/Sayantanmukherjee6/Silent-night-animation-video/blob/main/15secs_workflow.png)
- After having all of the videos and audios, I used IMovie to stich them together(removed most of the lipsync videos as they were not perfect and relied on the short videos). Here is a snapshot of the IMovie workflow:
![IMovie](https://github.com/Sayantanmukherjee6/Silent-night-animation-video/blob/main/imovie.png)

# Time took create this entire thing
- Around two week. The problem was with good workflow, creating character lora, I2V extend workflow and testing took longer as I was using RTX 3060 and obviously I had to juggle between my job, family and this work ðŸ˜ž.
- After I had all my workflows ready, it took around 1 and half day for generating this video. I was mainly having issue with story boarding and consistency. I used RTX 5090 to speed things up.

# References and Inspiration
- [ComfyUIStudio](https://www.youtube.com/@ComfyUIstudio)
- [Mickmumpitz](https://www.youtube.com/@mickmumpitz) - Free workflows are too good.
- [Benjiâ€™s AI Playground](https://www.youtube.com/@BenjisAIPlayground)
- [Ostris AI](https://www.youtube.com/@ostrisai)
- [The3MinuteNode](https://www.youtube.com/@The3MinuteNode)
- [Stable Diffusion Community Reddit](https://www.reddit.com/r/StableDiffusion/)
- [Wan2.2 tricks](https://civitai.com/articles/23629/i-spent-300-hours-on-wan-22-so-you-dont-have-to)
